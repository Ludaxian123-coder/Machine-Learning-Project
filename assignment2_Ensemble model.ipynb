{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#census_train = pd.read_csv('census_train.csv')\n",
    "#census_test = pd.read_csv('census_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process census_train and census_test to get X_train, y_train, X_test and y_test<br/>\n",
    "Question 2 continues here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, tree, model_selection\n",
    "import numpy as np\n",
    "from sklearn import tree, model_selection\n",
    "from sklearn import tree, ensemble, model_selection, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np \n",
    "from math import sqrt \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "pd.set_option(\"display.max_columns\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_train=pd.read_csv('taxi-train.csv',dtype={'vendor_id':str,'pickup_datetime':str,'pickup_longitude':float,\n",
    "                                                'dropoff_datetime':str,\n",
    "                                                'pickup_latitude':float,'dropoff_longitude':float,'dropoff_latitude':float,\n",
    "                                              'rate_code':float, 'passenger_count':int,'trip_distance':float,\n",
    "                                                'payment_type':str,'tip_paid':int,'fare_amount':float,'tip_amount':float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop column with null value count beyond  50% .\n",
    "thresh = len(taxi_train) * .5\n",
    "taxi_train.dropna(thresh = thresh, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace all NaN values to the average value of 'rate_code' column\n",
    "taxi_train['rate_code'].fillna(taxi_train['rate_code'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the time period spend in taxi In seconds.\n",
    "taxi_train['pickup_datetime']=pd.to_datetime(taxi_train['pickup_datetime'],format = '%Y-%m-%d %H:%M:%S+00:00')\n",
    "taxi_train['dropoff_datetime']=pd.to_datetime(taxi_train['dropoff_datetime'],format = '%Y-%m-%d %H:%M:%S+00:00')\n",
    "taxi_train['take_time_second']=(taxi_train['dropoff_datetime']-taxi_train['pickup_datetime']).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calulate the great circle distance between two points on the earth \n",
    "def circle_distance(lon1, lat1, lon2, lat2):\n",
    "\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    km = 6367 * c\n",
    "    return km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distance by longitude and latitude between two points.\n",
    "taxi_train['geographical distance']= circle_distance(taxi_train['pickup_longitude'],taxi_train['pickup_latitude'],taxi_train['dropoff_longitude'],taxi_train['dropoff_latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one-hot encoding for 'vendor_id' column\n",
    "taxi_train= pd.get_dummies(taxi_train, columns=['vendor_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CSH    545180\n",
       "CRD    434636\n",
       "CAS     33097\n",
       "Cas     27046\n",
       "Cre     26436\n",
       "CRE      2856\n",
       "NOC      1142\n",
       "UNK      1035\n",
       "DIS       300\n",
       "No        131\n",
       "Dis        28\n",
       "NA         23\n",
       "Name: payment_type, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#some categories number in 'payment_type' is very small , we will combine the small number value.\n",
    "taxi_train['payment_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the small number categories to one category ,then use one-hot encoding for 'payment_type' column\n",
    "payment_list=['CSH','CRD','CAS','Cas','Cre']\n",
    "taxi_train['payment_type'] =taxi_train['payment_type'].apply(lambda x: 'OTHER' if x not in payment_list else x)\n",
    "taxi_train= pd.get_dummies(taxi_train, columns=['payment_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop features that we will not used in traning model\n",
    "taxi_train.drop(labels=['pickup_datetime','dropoff_datetime','pickup_longitude',\n",
    "                        'pickup_latitude','dropoff_longitude','dropoff_latitude'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate_code</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tip_paid</th>\n",
       "      <th>take_time_second</th>\n",
       "      <th>geographical distance</th>\n",
       "      <th>vendor_id_CMT</th>\n",
       "      <th>vendor_id_DDS</th>\n",
       "      <th>vendor_id_VTS</th>\n",
       "      <th>payment_type_CAS</th>\n",
       "      <th>payment_type_CRD</th>\n",
       "      <th>payment_type_CSH</th>\n",
       "      <th>payment_type_Cas</th>\n",
       "      <th>payment_type_Cre</th>\n",
       "      <th>payment_type_OTHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>0.883927</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.50</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1</td>\n",
       "      <td>610.0</td>\n",
       "      <td>1.764546</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.60</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>553.0</td>\n",
       "      <td>2.331919</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.70</td>\n",
       "      <td>9.7</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1</td>\n",
       "      <td>960.0</td>\n",
       "      <td>1.892764</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.36</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1.491200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071905</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>0.831373</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071906</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.29</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1.464368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071907</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.80</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1</td>\n",
       "      <td>590.0</td>\n",
       "      <td>3.019187</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071908</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.584307</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071909</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.997352</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1071910 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rate_code  passenger_count  trip_distance  fare_amount  tip_amount  \\\n",
       "0              1.0                1           0.80          6.5        0.00   \n",
       "1              1.0                1           1.50          6.9        1.88   \n",
       "2              1.0                1           1.60          6.9        1.00   \n",
       "3              1.0                1           1.70          9.7        1.94   \n",
       "4              1.0                2           1.36          6.9        0.00   \n",
       "...            ...              ...            ...          ...         ...   \n",
       "1071905        1.0                1           0.50          5.5        0.00   \n",
       "1071906        1.0                1           1.29          8.5        0.00   \n",
       "1071907        1.0                1           2.80          8.9        1.88   \n",
       "1071908        1.0                1           0.50          4.5        0.00   \n",
       "1071909        1.0                1           0.93          6.1        0.00   \n",
       "\n",
       "         tip_paid  take_time_second  geographical distance  vendor_id_CMT  \\\n",
       "0               0             445.0               0.883927              1   \n",
       "1               1             610.0               1.764546              1   \n",
       "2               1             553.0               2.331919              1   \n",
       "3               1             960.0               1.892764              0   \n",
       "4               0             600.0               1.491200              0   \n",
       "...           ...               ...                    ...            ...   \n",
       "1071905         0             344.0               0.831373              1   \n",
       "1071906         0             600.0               1.464368              0   \n",
       "1071907         1             590.0               3.019187              1   \n",
       "1071908         0             264.0               0.584307              1   \n",
       "1071909         0             540.0               0.997352              0   \n",
       "\n",
       "         vendor_id_DDS  vendor_id_VTS  payment_type_CAS  payment_type_CRD  \\\n",
       "0                    0              0                 0                 0   \n",
       "1                    0              0                 0                 0   \n",
       "2                    0              0                 0                 0   \n",
       "3                    0              1                 0                 1   \n",
       "4                    0              1                 0                 0   \n",
       "...                ...            ...               ...               ...   \n",
       "1071905              0              0                 0                 0   \n",
       "1071906              0              1                 0                 1   \n",
       "1071907              0              0                 0                 1   \n",
       "1071908              0              0                 0                 0   \n",
       "1071909              0              1                 0                 0   \n",
       "\n",
       "         payment_type_CSH  payment_type_Cas  payment_type_Cre  \\\n",
       "0                       1                 0                 0   \n",
       "1                       0                 0                 1   \n",
       "2                       0                 0                 1   \n",
       "3                       0                 0                 0   \n",
       "4                       1                 0                 0   \n",
       "...                   ...               ...               ...   \n",
       "1071905                 1                 0                 0   \n",
       "1071906                 0                 0                 0   \n",
       "1071907                 0                 0                 0   \n",
       "1071908                 1                 0                 0   \n",
       "1071909                 1                 0                 0   \n",
       "\n",
       "         payment_type_OTHER  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "...                     ...  \n",
       "1071905                   0  \n",
       "1071906                   0  \n",
       "1071907                   0  \n",
       "1071908                   0  \n",
       "1071909                   0  \n",
       "\n",
       "[1071910 rows x 17 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_column=[0,1,2,5,6,7,8,9,10,11,12,13,14,15,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get train,validation and test data set , and target value only choose 'fare_amount'.\n",
    "X_train_fare, X_test_fare, y_train_fare, y_test_fare= train_test_split(taxi_train.iloc[:,select_column], taxi_train.iloc[:,3], test_size=0.2, random_state=1)\n",
    "\n",
    "X_train_fare, X_val_fare, y_train_fare, y_val_fare= train_test_split(X_train_fare, y_train_fare, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get train,validation and test data set , and  target value only choose 'tip_amount'.\n",
    "X_train_tip, X_test_tip, y_train_tip, y_test_tip= train_test_split(taxi_train.iloc[:,select_column], taxi_train.iloc[:,4], test_size=0.2, random_state=1)\n",
    "\n",
    "X_train_tip, X_val_tip, y_train_tip, y_val_tip= train_test_split(X_train_tip, y_train_tip, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model of RandomForestRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "param_RF={'n_estimators' : range(10,300,20),\n",
    "                     'min_samples_split': range(10,300,20),\n",
    "                     'max_features':range(5,15,2),\n",
    "                     'min_samples_leaf':range(10,200,20)\n",
    "                    }\n",
    "\n",
    "rf_cv=RandomizedSearchCV(RandomForestRegressor(),param_RF,random_state = 1,n_iter=10,refit=True,verbose = 3,n_jobs=-1,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  To predicting target variable 'fare_amount ' with RandomForstRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-19-902ec7e334d6>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-19-902ec7e334d6>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    rf_cv.fit(X_train_fare,y_train_fare，validation_data==(X_val_fare, y_val_fare))\u001b[0m\n\u001b[1;37m                                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "rf_cv.fit(X_train_fare,y_train_fare)\n",
    "print('Best parameter for fare_amount in RandomForestRegressor: ',rf_cv.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for validation data set for target variable fare_amount in RandomForestRegressor model:  1.2140830025925857\n",
      "RMSE for test data set with target variable fare_amount in RandomForestRegressor model:  1.256915143388508\n"
     ]
    }
   ],
   "source": [
    "#Testing the model trained my training data set accuracy by validation data set with evaluation metrics as RMSE. \n",
    "predict_val_fare=rf_cv.predict(X_val_fare)\n",
    "RMSE_RF_val_fare = sqrt(mean_squared_error(y_val_fare,predict_val_fare))\n",
    "predict_test_fare=rf_cv.predict(X_test_fare)\n",
    "RMSE_RF_test_fare = sqrt(mean_squared_error(y_test_fare,predict_test_fare))\n",
    "print('RMSE for validation data set for target variable fare_amount in RandomForestRegressor model: ',RMSE_RF_val_fare)\n",
    "print('RMSE for test data set with target variable fare_amount in RandomForestRegressor model: ',RMSE_RF_test_fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance for target variable fare_amount in RandomForestRegressor [1.38920371e-02 2.93218477e-04 3.09064765e-01 1.42533400e-03\n",
      " 4.89069212e-01 1.78444002e-01 8.19404902e-05 2.10285670e-04\n",
      " 8.19119429e-05 4.50973496e-04 4.95535238e-03 1.26533301e-03\n",
      " 3.04128676e-04 4.37944746e-04 2.35610528e-05]\n"
     ]
    }
   ],
   "source": [
    "#Use the best parameter to build a RandomForestRegressor and fit with test data to get the feature importance \n",
    "rf_fare=RandomForestRegressor(n_estimators=190,min_samples_split=190,max_features=5,min_samples_leaf=10,random_state = 1)\n",
    "rf_fare.fit(X_test_fare,y_test_fare)\n",
    "print('Feature importance for target variable fare_amount in RandomForestRegressor',rf_fare.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most importance of 5 parameters for fare_amount:     'rate_code' ,'passenger_count\t','take_time_second','geographical distance','tip_paid'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  To predicting target variable 'tip_amount ' with RandomForstRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'max_features': range(5, 15, 2),\n",
       "                                        'min_samples_leaf': range(10, 200, 20),\n",
       "                                        'min_samples_split': range(10, 300, 20),\n",
       "                                        'n_estimators': range(10, 300, 20)},\n",
       "                   random_state=1, verbose=3)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv.fit(X_train_tip,y_train_tip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for validation data set for target variable tip_amount in RandomForestRegressor model:  0.5543038138024592\n",
      "RMSE for test data set with target variable tip_amount in RandomForestRegressor model:  0.6392389685359925\n",
      "Best parameter for tip_amount in RandomForestRegressor:  {'n_estimators': 190, 'min_samples_split': 190, 'min_samples_leaf': 10, 'max_features': 5}\n"
     ]
    }
   ],
   "source": [
    "#Testing the model trained my training data set accuracy by validation data set with evaluation metrics as RMSE. \n",
    "predict_val_tip=rf_cv.predict(X_val_tip)\n",
    "RMSE_RF_val_tip = sqrt(mean_squared_error(y_val_tip,predict_val_tip ))\n",
    "predict_test_tip=rf_cv.predict(X_test_tip)\n",
    "RMSE_RF_test_tip = sqrt(mean_squared_error(y_test_tip,predict_test_tip))\n",
    "print('RMSE for validation data set for target variable tip_amount in RandomForestRegressor model: ',RMSE_RF_val_tip)\n",
    "print('RMSE for test data set with target variable tip_amount in RandomForestRegressor model: ',RMSE_RF_test_tip)\n",
    "print('Best parameter for tip_amount in RandomForestRegressor: ',rf_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance for target variable tip_amount in RandomForestRegressor [4.32788034e-03 6.40951793e-04 6.09280463e-02 4.16372621e-01\n",
      " 8.31439820e-02 2.73993717e-02 4.05647564e-04 6.45529268e-05\n",
      " 3.40528960e-04 4.18228318e-03 2.55841494e-01 1.33933941e-01\n",
      " 3.08851102e-03 8.75626834e-03 5.73920223e-04]\n"
     ]
    }
   ],
   "source": [
    "#Use the best parameter to build a RandomForestRegressor and fit with test data to get the feature importance \n",
    "rf_tip=RandomForestRegressor(n_estimators=190,min_samples_split=190,max_features=5, \n",
    "                             min_samples_leaf=10,random_state = 1)\n",
    "rf_tip.fit(X_test_tip,y_test_tip)\n",
    "print('Feature importance for target variable tip_amount in RandomForestRegressor',rf_tip.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Most importance of 5 parameters for tip_amount: 'take_time_second','geographical distance', 'rate_code','passenger_count', 'tip_paid'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model of  AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "param_Ada={'n_estimators' : range(10,150,20),\n",
    "           'learning_rate':[0.0001,0.001,0.01,0.1,1,10,100],\n",
    "           'loss':['linear', 'square', 'exponential']\n",
    "                    }\n",
    "Ada_cv=RandomizedSearchCV(AdaBoostRegressor(),param_Ada,random_state = 1,n_iter=10,refit=True,verbose = 3,n_jobs=-1,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To predicting target variable 'fare_amount ' with AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=AdaBoostRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.0001, 0.001, 0.01,\n",
       "                                                          0.1, 1, 10, 100],\n",
       "                                        'loss': ['linear', 'square',\n",
       "                                                 'exponential'],\n",
       "                                        'n_estimators': range(10, 150, 20)},\n",
       "                   random_state=1, verbose=3)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ada_cv.fit(X_train_fare,y_train_fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for validation data set for target variable fare_amount in AdaBoostRegressor model:  1.8397551952148394\n",
      "RMSE for test data set with target variable fare_amount in AdaBoostRegressor model:  1.885196487215237\n",
      "Best parameter for fare_amount in AdaBoostRegressor:  {'n_estimators': 70, 'loss': 'exponential', 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "#Testing the model trained my training data set accuracy by validation data set with evaluation metrics as RMSE. \n",
    "predict_val_fare=Ada_cv.predict(X_val_fare)\n",
    "RMSE_Ada_val_fare = sqrt(mean_squared_error(y_val_fare,predict_val_fare))\n",
    "predict_test_fare=Ada_cv.predict(X_test_fare)\n",
    "RMSE_Ada_test_fare = sqrt(mean_squared_error(y_test_fare,predict_test_fare))\n",
    "print('RMSE for validation data set for target variable fare_amount in AdaBoostRegressor model: ',RMSE_Ada_val_fare)\n",
    "print('RMSE for test data set with target variable fare_amount in AdaBoostRegressor model: ',RMSE_Ada_test_fare)\n",
    "print('Best parameter for fare_amount in AdaBoostRegressor: ',Ada_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance for target variable fare_amount in RandomForestRegressor [0.01254746 0.         0.14189514 0.         0.8455574  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "#Use the best parameter to build a RandomForestRegressor and fit with test data to get the feature importance \n",
    "Ada_fare=AdaBoostRegressor(n_estimators=70,learning_rate= 0.01,loss='exponential' ,random_state = 1)\n",
    "Ada_fare.fit(X_test_fare,y_test_fare)\n",
    "print('Feature importance for target variable fare_amount in RandomForestRegressor',Ada_fare.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Most importance of 5 features for fare_amount: 'trip_distance','passenger_count','rate_code','take_time_second','tip_paid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To predicting target variable 'tip_amount ' with AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=AdaBoostRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.0001, 0.001, 0.01,\n",
       "                                                          0.1, 1, 10, 100],\n",
       "                                        'loss': ['linear', 'square',\n",
       "                                                 'exponential'],\n",
       "                                        'n_estimators': range(10, 150, 20)},\n",
       "                   random_state=1, verbose=3)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ada_cv.fit(X_train_tip,y_train_tip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for validation data set for target variable tip_amount in AdaBoostRegressor model:  0.5858971543296739\n",
      "RMSE for test data set with target variable tip_amount in AdaBoostRegressor model:  0.6652876056831685\n",
      "Best parameter for tip_amount in AdaBoostRegressor:  {'n_estimators': 90, 'loss': 'square', 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "#Testing the model trained my training data set accuracy by validation data set with evaluation metrics as RMSE. \n",
    "predict_val_tip=Ada_cv.predict(X_val_tip)\n",
    "RMSE_Ada_val_tip = sqrt(mean_squared_error(y_val_tip,predict_val_tip ))\n",
    "predict_test_tip=Ada_cv.predict(X_test_tip)\n",
    "RMSE_Ada_test_tip = sqrt(mean_squared_error(y_test_tip,predict_test_tip))\n",
    "print('RMSE for validation data set for target variable tip_amount in AdaBoostRegressor model: ',RMSE_Ada_val_tip)\n",
    "print('RMSE for test data set with target variable tip_amount in AdaBoostRegressor model: ',RMSE_Ada_test_tip)\n",
    "print('Best parameter for tip_amount in AdaBoostRegressor: ',Ada_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance for target variable tip_amount in AdaBoostRegressor [6.00629368e-02 1.12548697e-03 1.31060215e-01 1.85619441e-03\n",
      " 7.85990954e-01 1.47706741e-02 0.00000000e+00 0.00000000e+00\n",
      " 1.80661397e-04 0.00000000e+00 4.95287726e-03 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "#Use the best parameter to build a RandomForestRegressor and fit with test data to get the feature importance\n",
    "Ada_tip=AdaBoostRegressor(n_estimators=90,loss='square',learning_rate=0.01,random_state = 1)\n",
    "Ada_tip.fit(X_test_fare,y_test_fare)\n",
    "print('Feature importance for target variable tip_amount in AdaBoostRegressor',Ada_tip.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most importance of 5 features for tip_amount: 'take_time_second','trip_distance','rate_code','geographical_distance'，'passenger_count'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model of GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "param_Gra={'n_estimators' : range(10,151,20),\n",
    "           'learning_rate':[0.0001,0.001,0.01,0.1,1,10,100],\n",
    "           'loss':['ls', 'lad', 'huber','quantile'],\n",
    "          'min_samples_split': range(10,300,20),\n",
    "             'max_features':range(5,15,2),\n",
    "             'min_samples_leaf':range(10,200,20)\n",
    "                    }\n",
    "Gra_cv=RandomizedSearchCV(GradientBoostingRegressor(),param_Gra,random_state = 1,n_iter=15,refit=True,verbose = 3,n_jobs=-1,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To predicting target variable 'fare_amount ' with GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\28491\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [-4.13532523e+209  1.56961231e-003  3.44500541e-001  9.15489157e-001\n",
      "  9.27223462e-001  7.37036423e-001 -1.57447579e+000 -3.48277570e+119\n",
      " -8.40235021e+285  3.26582647e-002             -inf -1.54439463e+000\n",
      " -1.86769771e+199  6.98072096e-001 -2.73519788e+171]\n",
      "  warnings.warn(\n",
      "C:\\Users\\28491\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:925: RuntimeWarning: invalid value encountered in subtract\n",
      "  array_stds = np.sqrt(np.average((array -\n",
      "C:\\Users\\28491\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:925: RuntimeWarning: overflow encountered in square\n",
      "  array_stds = np.sqrt(np.average((array -\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=GradientBoostingRegressor(), n_iter=15,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.0001, 0.001, 0.01,\n",
       "                                                          0.1, 1, 10, 100],\n",
       "                                        'loss': ['ls', 'lad', 'huber',\n",
       "                                                 'quantile'],\n",
       "                                        'max_features': range(5, 15, 2),\n",
       "                                        'min_samples_leaf': range(10, 200, 20),\n",
       "                                        'min_samples_split': range(10, 300, 20),\n",
       "                                        'n_estimators': range(10, 151, 20)},\n",
       "                   random_state=1, verbose=3)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gra_cv.fit(X_train_fare,y_train_fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for validation data set for target variable fare_amount in GradientBoostingRegressor model:  1.0823883339147273\n",
      "RMSE for test data set with target variable fare_amount in GradientBoostingRegressor model:  1.1243522795156162\n",
      "Best parameter for fare_amount in GradientBoostingRegressor:  {'n_estimators': 110, 'min_samples_split': 70, 'min_samples_leaf': 30, 'max_features': 7, 'loss': 'ls', 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "#Testing the model trained my training data set accuracy by validation data set with evaluation metrics as RMSE. \n",
    "predict_val_fare=Gra_cv.predict(X_val_fare)\n",
    "RMSE_Gra_val_fare = sqrt(mean_squared_error(y_val_fare,predict_val_fare))\n",
    "predict_test_fare=Gra_cv.predict(X_test_fare)\n",
    "RMSE_Gra_test_fare = sqrt(mean_squared_error(y_test_fare,predict_test_fare))\n",
    "print('RMSE for validation data set for target variable fare_amount in GradientBoostingRegressor model: ',RMSE_Gra_val_fare)\n",
    "print('RMSE for test data set with target variable fare_amount in GradientBoostingRegressor model: ',RMSE_Gra_test_fare)\n",
    "print('Best parameter for fare_amount in GradientBoostingRegressor: ',Gra_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance for target variable fare_amount in GradientBoostingRegressor [3.71072776e-02 1.33184668e-04 3.06539373e-01 7.57890875e-05\n",
      " 5.20002494e-01 1.29518335e-01 4.50168893e-04 2.68997876e-04\n",
      " 2.12021096e-04 6.84007580e-04 3.41585806e-03 3.34927064e-04\n",
      " 5.56082760e-04 6.98863498e-04 2.61964622e-06]\n"
     ]
    }
   ],
   "source": [
    "#Use the best parameter to build a RandomForestRegressor and fit with test data to get the feature importance \n",
    "Gra_fare=GradientBoostingRegressor(n_estimators=110 ,min_samples_split=70 ,max_features= 7,\n",
    "                               min_samples_leaf=30 ,random_state = 1)\n",
    "Gra_fare.fit(X_test_fare,y_test_fare)\n",
    "print('Feature importance for target variable fare_amount in GradientBoostingRegressor',Gra_fare.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most importance of 5 features for fare_amount: 'take_time_second','trip_distance','geographical distance','rate_code','payment_CRD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To predicting target variable 'tip_amount ' with GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\28491\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [-8.15454645e+203  1.32393148e-003  2.93457205e-001  6.99311133e-001\n",
      "  7.01147073e-001  4.96654534e-001 -1.38024949e+000 -1.54234152e+011\n",
      " -4.42843891e+286 -2.74239616e-001             -inf -1.33289165e+000\n",
      " -8.86623384e+199  5.65610087e-001 -6.18144215e+171]\n",
      "  warnings.warn(\n",
      "C:\\Users\\28491\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:925: RuntimeWarning: invalid value encountered in subtract\n",
      "  array_stds = np.sqrt(np.average((array -\n",
      "C:\\Users\\28491\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:925: RuntimeWarning: overflow encountered in square\n",
      "  array_stds = np.sqrt(np.average((array -\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=GradientBoostingRegressor(), n_iter=15,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.0001, 0.001, 0.01,\n",
       "                                                          0.1, 1, 10, 100],\n",
       "                                        'loss': ['ls', 'lad', 'huber',\n",
       "                                                 'quantile'],\n",
       "                                        'max_features': range(5, 15, 2),\n",
       "                                        'min_samples_leaf': range(10, 200, 20),\n",
       "                                        'min_samples_split': range(10, 300, 20),\n",
       "                                        'n_estimators': range(10, 151, 20)},\n",
       "                   random_state=1, verbose=3)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gra_cv.fit(X_train_tip,y_train_tip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for validation data set for target variable tip_amount in GradientBoostingRegressor model:  0.5536392480597323\n",
      "RMSE for test data set with target variable tip_amount in GradientBoostingRegressor model:  0.6384721447109518\n",
      "Best parameter for tip_amount in GradientBoostingRegressor:  {'n_estimators': 110, 'min_samples_split': 70, 'min_samples_leaf': 30, 'max_features': 7, 'loss': 'ls', 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "#Testing the model trained my training data set accuracy by validation data set with evaluation metrics as RMSE. \n",
    "predict_val_tip=Gra_cv.predict(X_val_tip)\n",
    "RMSE_Gra_val_tip = sqrt(mean_squared_error(y_val_tip,predict_val_tip ))\n",
    "predict_test_tip=Gra_cv.predict(X_test_tip)\n",
    "RMSE_Gra_test_tip = sqrt(mean_squared_error(y_test_tip,predict_test_tip))\n",
    "print('RMSE for validation data set for target variable tip_amount in GradientBoostingRegressor model: ',RMSE_Gra_val_tip)\n",
    "print('RMSE for test data set with target variable tip_amount in GradientBoostingRegressor model: ',RMSE_Gra_test_tip)\n",
    "print('Best parameter for tip_amount in GradientBoostingRegressor: ',Gra_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance for target variable tip_amount in GradientBoostingRegressor [8.51467713e-03 1.93616796e-05 4.44367664e-02 5.07058245e-01\n",
      " 9.99257422e-02 1.79487862e-02 1.65483403e-04 3.23097793e-05\n",
      " 4.70565050e-05 1.44161389e-04 1.21466077e-01 1.97875453e-01\n",
      " 5.88908646e-05 2.30143009e-03 5.55933993e-06]\n"
     ]
    }
   ],
   "source": [
    "#Use the best parameter to build a RandomForestRegressor and fit with test data to get the feature importance\n",
    "Gra_tip=GradientBoostingRegressor(n_estimators=190,min_samples_split=190,max_features=5,min_samples_leaf=10,random_state = 1)\n",
    "Gra_tip.fit(X_test_tip,y_test_tip)\n",
    "print('Feature importance for target variable tip_amount in GradientBoostingRegressor',Gra_tip.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most importance of 5 features for tip_amount: 'tip_paid','payment_type_CSH','payment_type_CRD','take_time_second','trip_distance'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For target variable fare_amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Random Forest</b><br/>\n",
    "Objective metric on test:  1.256915143388508 <br/>\n",
    "Parameters: {'n_estimators': 190, 'min_samples_split': 190, 'min_samples_leaf': 10, 'max_features': 5} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>AdaBoost</b><br/>\n",
    "Objective metric on test:  1.885196487215237 <br/>\n",
    "Parameters:  {'n_estimators': 70, 'loss': 'exponential', 'learning_rate': 0.01} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Gradient Boosting</b><br/>\n",
    "Objective metric on test:  1.1243522795156162<br/>\n",
    "Parameters:  {'n_estimators': 110, 'min_samples_split': 70, 'min_samples_leaf': 30, 'max_features': 7, 'loss': 'ls', 'learning_rate': 0.1} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Important Features</b>\n",
    "\n",
    "| Classifier | RandomForest | AdaBoost | GradientBoosting |\n",
    "| --- | --- | --- | --- |\n",
    "| Feature 1 |rate_code|trip_distance |take_time_second  \n",
    "| Feature 2 |passenger_count|passenger_count|trip_distance\n",
    "| Feature 3 |take_time_second|rate_code|geographical distance\n",
    "| Feature 4 |geographical distance|take_time_second|rate_code\n",
    "| Feature 5 |tip_paid|tip_paid|payment_CRD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For target variable tip_amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Random Forest</b><br/>\n",
    "Objective metric on test: 0.6392389685359925<br/>\n",
    "Parameters: {'n_estimators': 190, 'min_samples_split': 190, 'min_samples_leaf': 10, 'max_features': 5}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>AdaBoost</b><br/>\n",
    "Objective metric on test: 0.6652876056831685<br/>\n",
    "Parameters: {'n_estimators': 90, 'loss': 'square', 'learning_rate': 0.01}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Gradient Boosting</b><br/>\n",
    "Objective metric on test: 0.6384721447109518<br/>\n",
    "Parameters: {'n_estimators': 110, 'min_samples_split': 70, 'min_samples_leaf': 30, 'max_features': 7, 'loss': 'ls', 'learning_rate': 0.1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Important Features</b>\n",
    "\n",
    "| Classifier | RandomForest | AdaBoost | GradientBoosting |\n",
    "| --- | --- | --- | --- |\n",
    "| Feature 1 | take_time_second|take_time_second|tip_paid\n",
    "| Feature 2 |geographical distance|trip_distance|payment_type_CSH\n",
    "| Feature 3 |rate_code|rate_code|payment_type_CRD|payment_type_CRD\n",
    "| Feature 4 |passenger_count|geographical_distance|take_time_second\n",
    "| Feature 5 |tip_paid|passenger_count|trip_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "taxi_test=pd.read_csv('taxi-test.csv',dtype={'vendor_id':str,'pickup_datetime':str,'pickup_longitude':float,\n",
    "                                                'dropoff_datetime':str,\n",
    "                                                'pickup_latitude':float,'dropoff_longitude':float,'dropoff_latitude':float,\n",
    "                                              'rate_code':float, 'passenger_count':int,'trip_distance':float,\n",
    "                                                'payment_type':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = len(taxi_test) * .5\n",
    "taxi_test.dropna(thresh = thresh, axis = 1, inplace = True)\n",
    "#valmean=pd.to_numeric(taxi_train['rate_code'], errors='coerce').mean()\n",
    "taxi_test['rate_code'].fillna(taxi_test['rate_code'].mean(),inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_test['pickup_datetime']=pd.to_datetime(taxi_test['pickup_datetime'],format = '%Y-%m-%d %H:%M:%S+00:00')\n",
    "taxi_test['dropoff_datetime']=pd.to_datetime(taxi_test['dropoff_datetime'],format = '%Y-%m-%d %H:%M:%S+00:00')\n",
    "taxi_test['take_time_second']=(taxi_test['dropoff_datetime']-taxi_test['pickup_datetime']).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calulate the great circle distance between two points on the earth \n",
    "def circle_distance(lon1, lat1, lon2, lat2):\n",
    "\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    km = 6367 * c\n",
    "    return km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_test['geographical distance']= circle_distance(taxi_test['pickup_longitude'],taxi_test['pickup_latitude'],taxi_test['dropoff_longitude'],taxi_test['dropoff_latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_test= pd.get_dummies(taxi_test, columns=['vendor_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CSH    5392\n",
       "CRD    4460\n",
       "CAS     344\n",
       "Cas     302\n",
       "Cre     272\n",
       "CRE      42\n",
       "UNK       8\n",
       "NOC       7\n",
       "DIS       1\n",
       "Name: payment_type, dtype: int64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_test['payment_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the small value to 'OTHER'\n",
    "payment_list=['CSH','CRD','CAS','Cas','Cre','CRE']\n",
    "taxi_test['payment_type'] =taxi_test['payment_type'].apply(lambda x: 'OTHER' if x not in payment_list else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_test= pd.get_dummies(taxi_test, columns=['payment_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_test.drop(labels=['pickup_datetime','dropoff_datetime','pickup_longitude',\n",
    "                        'pickup_latitude','dropoff_longitude','dropoff_latitude'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accroding the model metrics result above, Gradient Boosting has the best RMSE which is  1.1243522795156162 in predict 'fare_amount' . So, we use GradientBoostingRegressor with parameters {'n_estimators': 110, 'min_samples_split': 70, 'min_samples_leaf': 30, 'max_features': 7, 'loss': 'ls', 'learning_rate': 0.1} to predict 'fare_amount' value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gra_fare is the model trained by taxi-train data set test part with best parameters.\n",
    "target_fare_amount=Gra_fare.predict(taxi_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.85655745, 4.41725918, 7.37879595, ..., 6.92783764, 4.04101195,\n",
       "       8.64778862])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicted fare_amount in taxi-test dataset\n",
    "target_fare_amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accroding the model metrics result above, Gradient Boosting has the best RMSE which is   0.6384721447109518 in 'predict tip_amount'. So, we use GradientBoostingRegressor with parameters {'n_estimators': 110, 'min_samples_split': 70, 'min_samples_leaf': 30, 'max_features': 7, 'loss': 'ls', 'learning_rate': 0.1} to predict 'tip_amount' value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gra_tip is the model trained by taxi-train data set test part with best parameters.\n",
    "target_fare_amount=Gra_tip.predict(taxi_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.41860743, 1.60606063, 1.66796867, ..., 1.78373896, 1.53489041,\n",
       "       1.71104303])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicted tip_amount in taxi-test dataset\n",
    "target_fare_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
